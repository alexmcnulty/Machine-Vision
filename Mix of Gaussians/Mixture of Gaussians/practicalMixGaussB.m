function r=practicalMixGaussB

%The goal of this practical is to generate some data from a one-dimensional
%mixtures of Gaussians model, and subsequently to fit a mixtures of Gaussians model to
%this data, to recover the original parameters.

%You should use this template for your code and fill in the missing 
%sections marked "TO DO"

%close all open plots
close all;




% TO DO: Note (again) that you should NOT be using functions like normpdf and
% normfit or other functions from Statistics Toolbox in sampling from or
% fitting your distributions in this or further parts of this practical.
% Optionally, you can try comparing your results to those produced by those
% functions, but our goal here is to learn what is happening!





%define the True parameters for mixture of k Gaussians
%we will represent the mixtures of Gaussians as a Matlab structure
%we are working in 1 dimension, but if we were in d dimenisions, the mean field
%will be a dxk matrix and the cov field will be a dxdxk matrix.
mixGaussTrue.k = 2;
mixGaussTrue.d = 1;
mixGaussTrue.weight = [0.3 0.7];
mixGaussTrue.mean = [-1 1.5];
mixGaussTrue.cov = reshape([0.5 0.25],1,1,2);

%define number of samples to generate
nData = 400;

%generate data from the mixture of Gaussians
%TO DO - fill in this routine (below)
data = mixGaussGen1d(mixGaussTrue,nData);

%draw data, True Gaussians
figure;
drawEMData1d(data,mixGaussTrue);
drawnow;
%saveas( gcf, 'True_Gaussian', 'jpg' );
%define number of components to estimate
nGaussEst = 2;

%fit mixture of Gaussians (Pretend someone handed you some data. Now what?)
%TO DO fill in this routine (below)
figure;
mixGaussEst = fitMixGauss1d(data,nGaussEst);




%==========================================================================
%==========================================================================

%the goal of this function is to generate data from a one-dimensional
%mixture of Gaussians structure.
function data = mixGaussGen1d(mixGauss,nData);

%create space for output data
data = zeros(1,nData);
%for each data point
for (cData =1:nData)
    %randomly choose Gaussian according to probability distributions
    h = sampleFromDiscrete(mixGauss.weight);
    %draw a sample from the appropriate Gaussian distribution
    %TO DO (d)- replace this
    data(:,cData) = mixGauss.mean(h)+mixGauss.cov(h).^0.5*randn(1);
end;
    
%==========================================================================
%==========================================================================

function mixGaussEst = fitMixGauss1d(data,k);
        
nData = size(data,2); %how many columns are in the data.

%MAIN E-M ROUTINE 
%there are nData data points, and there is a hidden variable associated
%with each.  If the hidden variable is 0 this indicates that the data was
%generated by the first Gaussian.  If the hidden variable is 1 then this
%indicates that the hidden variable was generated by the second Gaussian
%etc.

responsibilities =zeros(k, nData); %k represents the # of classes 

%in the E-M algorithm, we calculate a complete posterior distribution over
%the (nData) hidden variables in the E-Step.  In the M-Step, we
%update the parameters of the Gaussians (mean, cov, w).  

%we will initialize the values to random values
mixGaussEst.d = 1;
mixGaussEst.k = k;
mixGaussEst.weight = (1/k)*ones(1,k); %ones creates array of all ones with (i,j) i rows & j columns
mixGaussEst.mean = 2*randn(1,k);
mixGaussEst.cov = 0.1+1.5*rand(1,1,k);

%calculate current likelihood
%TO DO - fill in this routine
logLike = getMixGaussLogLike(data,mixGaussEst);
fprintf('Log Likelihood Iter 0 : %4.3f\n',logLike);

nIter = 20;
for (cIter = 1:nIter)
  
   % ===================== =====================
   %Expectation step
   % ===================== =====================
   numerator = zeros(k,nData);
   for (cData = 1:nData)
        %TO DO: fill in column of 'hidden' - caculate posterior probability that
        %this data point came from each of the Gaussians
        %replace this:
        for (i=1:k)
            numerator(i,cData) = calcGaussianProb(data(1,cData)',mixGaussEst.mean(1,i),mixGaussEst.cov(1,i))';
        end
   end;
   responsibilities=numerator./repmat(sum(numerator,1),k,1);

   %calculate the log likelihood
   logLike = getMixGaussLogLike(data,mixGaussEst);
   fprintf('Log Likelihood After E-Step Iter %d : %4.3f\n',cIter,logLike);

   %calculate the bound
   %TO DO - Fill in this routine
   bound = getMixGaussBound(data,mixGaussEst,responsibilities);
   fprintf('Bound After E-Step Iter %d : %4.3f\n',cIter,bound)

   % ===================== =====================
   %Maximization Step
   % ===================== =====================
   %for each constituent Gaussian
   for (cGauss = 1:k) 
        %TO DO:  Update weighting parameters mixGauss.weight based on the total
        %posterior probability associated with each Gaussian. Replace this:
        mixGaussEst.weight(cGauss) = sum(responsibilities(cGauss,:))/length(responsibilities(cGauss,:)); 
   
        %TO DO:  Update mean parameters mixGauss.mean by weighted average
        %where weights are given by posterior probability associated with
        %Gaussian.  Replace this:
        mixGaussEst.mean(cGauss) = sum(responsibilities(cGauss,:).*data(:,:))/sum(responsibilities(cGauss,:));
        
        %TO DO:  Update covarance parameter based on weighted average of
        %square distance from update mean, where weights are given by
        %posterior probability associated with Gaussian
        
        
        for cData=1:nData
            
           mixGaussEst.cov(:,:,cGauss) = mixGaussEst.cov(:,:,cGauss) + ...
           responsibilities(cGauss,cData)*((data(:,cData)-mixGaussEst.mean(:,cGauss))...
           *(data(:,cData)-mixGaussEst.mean(:,cGauss))');
        end
        
        mixGaussEst.cov(:,:,cGauss) = mixGaussEst.cov(:,:,cGauss) /sum(responsibilities(cGauss,:));
   end;
   
   %draw the new solution
   drawEMData1d(data,mixGaussEst);drawnow;
    %saveas( gcf, 'My_Gaussians_3', 'jpg' );
   %calculate the log likelihood
   logLike = getMixGaussLogLike(data,mixGaussEst);
   fprintf('Log Likelihood After M-Step Iter %d : %4.3f\n',cIter,logLike);

   %calculate the bound
   bound = getMixGaussBound(data,mixGaussEst,responsibilities);
   fprintf('Bound After M-Step Iter %d : %4.3f\n',cIter,bound);   
end;


%==========================================================================
%==========================================================================

%the goal of this routine is to calculate the log likelihood for the whole
%data set under a mixture of Gaussians model. We calculate the log because the
%likelihood will probably be a very small number that Matlab may not be
%able to represent.
function logLike = getMixGaussLogLike(data,mixGaussEst);

%find total number of data items
nData = size(data,2);

%initialize log likelihoods
logLike = 0;
%run through each data item
for(cData = 1:nData)
    like=0;

    thisData = data(:,cData);    
    %TO DO (e) - calculate likelihood of this data point under mixture of
    %Gaussians model. Replace this
    for (num= 1:size(mixGaussEst.weight))% 1:k
    like_n=calcGaussianProb(thisData,mixGaussEst.mean(1,num),mixGaussEst.cov(1,num))* mixGaussEst.weight(1,num) ;  
    like = like + like_n;
    end;
    %add to total log like
    logLike = logLike+log(like);        
end;

%==========================================================================
%==========================================================================

%the goal of this routine is to calculate the bound on the 
%log likelihood for the whole data set under a mixture of Gaussians model.
function bound = getMixGaussBound(data,mixGaussEst,responsibilities)

% %find total number of data items
nData = size(data,2);

%initialize bound
    bound = 0;

%run through each data item
for(cData = 1:nData)
    %extract this data
    thisData = data(:,cData);    
    boundValue=0;
    %TO DO - calculate contribution to bound of this datapoint
    %Replace this
   % p1 = bsxfun(@minus,data,mixGaussEst.mean(:,cGauss));
    
    
    for(i=1:size(responsibilities,1))
    BV = responsibilities(i,cData) *log(calcGaussianProb(thisData,mixGaussEst.mean(1,i)...
        ,mixGaussEst.cov(1,i))/responsibilities(i,cData)) ;
    
    boundValue= BV+ boundValue;
    end;
    
    %add to total log like
    bound = bound+boundValue;        
end;
% mixGaussEst.cov(:,:,cGauss) = bsxfun(@times,p1, responsibilities(cGauss,:))*p1'./sum(responsibilities(cGauss,:));

% for k = 1:2
    % BV = bsxfun(@times,responsibilities(k,:),log(mixGaussEst.weight(k)*calcGaussianProb(data(1,:)',mixGaussEst.mean(:,k),mixGaussEst.cov(:,:,k))));
%     bound = bound+BV;
% end
% bound = sum(sum(bound));


%==========================================================================
%==========================================================================

%The goal fo this routine is to draw the data in histogram form and plot
%the mixtures of Gaussian model on top of it.
function r = drawEMData1d(data,mixGauss)

%delete previous plot if it exists
hold off;
%bin the data to make a histogram
binWidth = 0.1;
binMin =-4;
binMax = 4;
xHist = binMin:binWidth:binMax;
yHist = hist(data,xHist)/(length(data)*binWidth);
bar(xHist,yHist,1);
%retain this plot
hold on;
%calculate Gaussian data
nGauss = mixGauss.k;
gaussEnvEst = zeros(size(xHist));
for (cGauss = 1:nGauss)
    %calculate weighted Gaussian values
    gaussProb = mixGauss.weight(cGauss)*getGaussProb(xHist,mixGauss.mean(cGauss),mixGauss.cov(cGauss));
    plot(xHist, gaussProb,'m-');
    %add to form envelope
    gaussEnvEst = gaussEnvEst+gaussProb;
end;
plot(xHist, gaussEnvEst,'g-');

%tidy up plot
xlabel('Data Value');
ylabel('Probability Density');
set(gca,'Box','Off');
set(gcf,'Color',[1 1 1]);
xlim([binMin binMax]);
ylim([0 max(yHist)*1.5]);

%==========================================================================
%==========================================================================

%draws a random sample from a discrete probability distribution using a
%rejection sampling method
function r = sampleFromDiscrete(probDist);

nIndex = length(probDist);
while(1)
    %choose random index
    r=ceil(rand(1)*nIndex);
    %choose random height
    randHeight = rand(1);
    %if height is less than probability value at this point in the
    %histogram then select
    if (randHeight<probDist(r))
        break;
    end;
end;
    
%==========================================================================
%==========================================================================
function like = calcGaussianProb(data,gaussMean,gaussCov)

%TO DO (b) - fill in this routine
%replace this
g = length(gaussMean);
p1 = gaussCov\(data - gaussMean);
output = (1/(((2*pi)^(g/2)) * det(gaussCov)))*(exp(-0.5*(data - gaussMean)' *p1));


like = output;

%subroutine to return gaussian probabilities
function prob = getGaussProb(x,mean,var)

prob = exp(-0.5.*((x-mean).^2)./(var));
prob = prob./ sqrt(2*pi*var);

